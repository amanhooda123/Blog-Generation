{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFsEqYiAgDtw",
        "outputId": "b4b4f19d-00d5-45ab-b1e5-c869174616af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Update this import statement\n",
        "from langchain_community.llms import CTransformers\n",
        "\n",
        "\n",
        "# Function to get a response from the LLama 2 model\n",
        "def getLLamaresponse(input_text, no_words, blog_style):\n",
        "    # LLama2 model initialization\n",
        "    llm = CTransformers(model='llama-2-7b-chat.ggmlv3.q8_0.bin',\n",
        "                    model_type='llama',\n",
        "                    config={'max_new_tokens': 256, 'temperature': 0.01})\n",
        "\n",
        "\n",
        "    # Prompt Template\n",
        "    template = \"\"\"\n",
        "        Write a blog for {blog_style} job profile on the topic '{input_text}'\n",
        "        within {no_words} words.\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"blog_style\", \"input_text\", \"no_words\"],\n",
        "                            template=template)\n",
        "\n",
        "    # Generate the response from the LLama 2 model\n",
        "    response = llm(prompt.format(blog_style=blog_style, input_text=input_text, no_words=no_words))\n",
        "    print(response)\n",
        "    return response\n",
        "\n",
        "# Streamlit app configuration\n",
        "st.set_page_config(page_title=\"Generate Blogs\",\n",
        "                   page_icon='ðŸ¤–',\n",
        "                   layout='centered',\n",
        "                   initial_sidebar_state='collapsed')\n",
        "\n",
        "st.header(\"Generate Blogs ðŸ¤–\")\n",
        "\n",
        "# User input for the blog topic\n",
        "input_text = st.text_input(\"Enter the Blog Topic\")\n",
        "\n",
        "# Columns for additional input fields\n",
        "col1, col2 = st.columns([5, 5])\n",
        "\n",
        "with col1:\n",
        "    no_words = st.text_input('Number of Words')\n",
        "with col2:\n",
        "    blog_style = st.selectbox('Writing the blog for',\n",
        "                              ('Researchers', 'Data Scientists', 'Common People'), index=0)\n",
        "\n",
        "# Button to trigger blog generation\n",
        "submit = st.button(\"Generate\")\n",
        "\n",
        "# Display the generated blog response\n",
        "if submit:\n",
        "    response = getLLamaresponse(input_text, no_words, blog_style)\n",
        "    st.write(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set your ngrok authtoken here\n",
        "ngrok.set_auth_token('2eNpJj14FmbWr5NXZaUNiQdCYC4_5a6HLq1PPBiiPLJWtknt6')\n",
        "\n",
        "# Setup a tunnel to the streamlit port 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UhENWk5ghTY",
        "outputId": "561777e5-a05d-449c-ab31-e83925021513"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://490f-34-106-86-140.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run streamlit_app.py &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lenk91nvgIFj",
        "outputId": "6539cfb5-2008-419f-d1dd-781435ea41a3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.106.86.140:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bUaGSCfPjqpB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}